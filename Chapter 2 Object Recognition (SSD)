import torch
import torchvision
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as T

# デバイスの設定 (GPUが利用可能ならそれを使う)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 事前学習済みのSSDモデルをロード (SSD300 with ResNet50 backbone)
model = torchvision.models.detection.ssd300_vgg16(pretrained=True)
model = model.to(device)
model.eval()  # モデルを評価モードに設定

# COCOデータセットのクラスラベル (物体クラス)
COCO_INSTANCE_CATEGORY_NAMES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
    'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',
    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',
    'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',
    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog',
    'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'TV',
    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

# 画像の読み込みと前処理
def load_image(image_path):
    image = Image.open(image_path)
    transform = T.Compose([T.Resize((300, 300)), T.ToTensor()])
    return transform(image).unsqueeze(0).to(device)

# 物体認識の実行
def detect_objects(model, image):
    with torch.no_grad():
        prediction = model(image)[0]  # 物体認識結果を取得
    return prediction

# 画像上に物体検出結果をプロット
def plot_results(image_path, prediction, threshold=0.5):
    image = Image.open(image_path)
    plt.figure(figsize=(10, 10))
    plt.imshow(image)

    # 予測されたボックスとラベルを描画
    for i in range(len(prediction['boxes'])):
        score = prediction['scores'][i].item()
        if score > threshold:  # スコアが閾値を超える場合のみ表示
            box = prediction['boxes'][i].cpu().numpy()
            label = COCO_INSTANCE_CATEGORY_NAMES[prediction['labels'][i].item()]
            plt.gca().add_patch(plt.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1],
                                              linewidth=2, edgecolor='r', facecolor='none'))
            plt.text(box[0], box[1], f'{label}: {score:.2f}', bbox=dict(facecolor='yellow', alpha=0.5))

    plt.axis('off')
    plt.show()

# メイン処理
image_path = 'sample_image.jpg'  # 使用する画像のパス
image = load_image(image_path)  # 画像を読み込み
prediction = detect_objects(model, image)  # 物体認識を実行
plot_results(image_path, prediction)  # 画像上に物体検出結果をプロット
